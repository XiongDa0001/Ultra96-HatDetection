{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")\n",
    "overlay.load_model(\"dpu_HatDetection.elf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "from dnndk import n2cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model post-processing'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''resize image with unchanged aspect ratio using padding'''\n",
    "def letterbox_image(image, size):\n",
    "    ih, iw, _ = image.shape\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    \n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "\n",
    "    image = cv2.resize(image, (nw,nh), interpolation=cv2.INTER_LINEAR)\n",
    "    new_image = np.ones((h,w,3), np.uint8) * 128\n",
    "    h_start = (h-nh)//2\n",
    "    w_start = (w-nw)//2\n",
    "    new_image[h_start:h_start+nh, w_start:w_start+nw, :] = image\n",
    "    return new_image\n",
    "\n",
    "'''image preprocessing'''\n",
    "def pre_process(image, model_image_size):\n",
    "    image = image[...,::-1]\n",
    "    image_h, image_w, _ = image.shape\n",
    " \n",
    "    if model_image_size != (None, None):\n",
    "        assert model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "        assert model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "        boxed_image = letterbox_image(image, tuple(reversed(model_image_size)))\n",
    "    else:\n",
    "        new_image_size = (image_w - (image_w % 32), image_h - (image_h % 32))\n",
    "        boxed_image = letterbox_image(image, new_image_size)\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0) \t\n",
    "    return image_data\n",
    "\n",
    "'''Get model classification information'''\t\n",
    "def get_class(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "'''Get model anchors value'''\n",
    "def get_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "    \n",
    "def _get_feats(feats, anchors, num_classes, input_shape):\n",
    "    num_anchors = len(anchors)\n",
    "    anchors_tensor = np.reshape(np.array(anchors, dtype=np.float32), [1, 1, 1, num_anchors, 2])\n",
    "    grid_size = np.shape(feats)[1:3]\n",
    "    nu = num_classes + 5\n",
    "    predictions = np.reshape(feats, [-1, grid_size[0], grid_size[1], num_anchors, nu])\n",
    "    grid_y = np.tile(np.reshape(np.arange(grid_size[0]), [-1, 1, 1, 1]), [1, grid_size[1], 1, 1])\n",
    "    grid_x = np.tile(np.reshape(np.arange(grid_size[1]), [1, -1, 1, 1]), [grid_size[0], 1, 1, 1])\n",
    "    grid = np.concatenate([grid_x, grid_y], axis = -1)\n",
    "    grid = np.array(grid, dtype=np.float32)\n",
    "\n",
    "    box_xy = (1/(1+np.exp(-predictions[..., :2])) + grid) / np.array(grid_size[::-1], dtype=np.float32)\n",
    "    box_wh = np.exp(predictions[..., 2:4]) * anchors_tensor / np.array(input_shape[::-1], dtype=np.float32)\n",
    "    box_confidence = 1/(1+np.exp(-predictions[..., 4:5]))\n",
    "    box_class_probs = 1/(1+np.exp(-predictions[..., 5:]))\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "def correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = np.array(input_shape, dtype = np.float32)\n",
    "    image_shape = np.array(image_shape, dtype = np.float32)\n",
    "    new_shape = np.around(image_shape * np.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2. / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = np.concatenate([\n",
    "        box_mins[..., 0:1],\n",
    "        box_mins[..., 1:2],\n",
    "        box_maxes[..., 0:1],\n",
    "        box_maxes[..., 1:2]\n",
    "    ], axis = -1)\n",
    "    boxes *= np.concatenate([image_shape, image_shape], axis = -1)\n",
    "    return boxes\n",
    "\n",
    "def boxes_and_scores(feats, anchors, classes_num, input_shape, image_shape):\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = _get_feats(feats, anchors, classes_num, input_shape)\n",
    "    boxes = correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = np.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = np.reshape(box_scores, [-1, classes_num])\n",
    "    return boxes, box_scores\t\n",
    "\n",
    "'''Draw detection frame'''\n",
    "def draw_bbox(image, bboxes, classes):\n",
    "    \"\"\"\n",
    "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
    "    \"\"\"\n",
    "    num_classes = len(classes)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        fontScale = 0.5\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = colors[class_ind]\n",
    "        bbox_thick = int((image_h + image_w) / 300)\n",
    "        c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
    "    return image\n",
    "\n",
    "def nms_boxes(boxes, scores):\n",
    "    \"\"\"Suppress non-maximal boxes.\n",
    "\n",
    "    # Arguments\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "\n",
    "    # Returns\n",
    "        keep: ndarray, index of effective boxes.\n",
    "    \"\"\"\n",
    "    nms_thresh=0.4\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2-x1+1)*(y2-y1+1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w1 = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h1 = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w1 * h1\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(ovr <= nms_thresh)[0]  # threshold\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\t\n",
    "  \n",
    "'''Model post-processing'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get model classification information\"\"\"\n",
    "classes_path = \"./new_classes.txt\"\n",
    "class_names = get_class(classes_path)\n",
    "\n",
    "\"\"\"Get model anchor value\"\"\"\n",
    "anchors_path = \"./yolo_anchors.txt\"\n",
    "anchors = get_anchors(anchors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(yolo_outputs, image_shape, class_names, anchors):\n",
    "    score_thresh = 0.75\n",
    "    class_names = get_class(classes_path)\n",
    "    anchors     = get_anchors(anchors_path)\n",
    "    anchor_mask = [[3, 4, 5], [1, 2, 3]]\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    \n",
    "    input_shape = np.shape(yolo_outputs[0])[1 : 3]\n",
    "    input_shape = np.array(input_shape)*32\n",
    "    \n",
    "    for i in range(len(yolo_outputs)):\n",
    "        _boxes, _box_scores = boxes_and_scores(yolo_outputs[i], anchors[anchor_mask[i]], len(class_names), input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = np.concatenate(boxes, axis = 0)\n",
    "    box_scores = np.concatenate(box_scores, axis = 0)\n",
    "    \n",
    "    mask = box_scores >= score_thresh\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(len(class_names)):\n",
    "        class_boxes_np = boxes[mask[:, c]]\n",
    "        class_box_scores_np = box_scores[:, c]\n",
    "        class_box_scores_np = class_box_scores_np[mask[:, c]]\n",
    "        nms_index_np = nms_boxes(class_boxes_np, class_box_scores_np) \n",
    "        class_boxes_np = class_boxes_np[nms_index_np]\n",
    "        class_box_scores_np = class_box_scores_np[nms_index_np]\n",
    "        classes_np = np.ones_like(class_box_scores_np, dtype = np.int32) * c\n",
    "        boxes_.append(class_boxes_np)\n",
    "        scores_.append(class_box_scores_np)\n",
    "        classes_.append(classes_np)\n",
    "    boxes_ = np.concatenate(boxes_, axis = 0)\n",
    "    scores_ = np.concatenate(scores_, axis = 0)\n",
    "    classes_ = np.concatenate(classes_, axis = 0)\n",
    "    \n",
    "    return boxes_, scores_, classes_\n",
    "\n",
    "\"\"\"DPU Kernel Name for yolov4_tiny\"\"\"\n",
    "KERNEL_CONV=\"HatDetection\"\n",
    "#libdpumodeltf_yolov3_voc.so\n",
    "\"\"\"DPU IN/OUT Name for yolov4_tiny\"\"\"\n",
    "CONV_INPUT_NODE=\"conv2d_1_convolution\"\n",
    "CONV_OUTPUT_NODE1=\"conv2d_21_convolution\"\n",
    "CONV_OUTPUT_NODE2=\"conv2d_24_convolution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Attach to DPU driver and prepare for running \"\"\"\n",
    "n2cube.dpuOpen()\n",
    "\n",
    "\"\"\" Create DPU Kernels for yolov4_tiny \"\"\"\n",
    "kernel = n2cube.dpuLoadKernel(KERNEL_CONV)\n",
    "\n",
    "\"\"\" Create DPU Tasks for yolov4_tiny \"\"\"\n",
    "task = n2cube.dpuCreateTask(kernel, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_jupyter(img_mat):\n",
    "    img_mat = cv2.cvtColor(img_mat, cv2.COLOR_BGR2RGB)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(img_mat).save(f, 'png')\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import time\n",
    "import cv2\n",
    "import base64\n",
    "def arrayShow(imageArray):\n",
    "    ret, png = cv2.imencode('.png', imageArray)\n",
    "    encoded = base64.b64encode(png)\n",
    "    return Image(data=encoded.decode('ascii'))\n",
    "#      _,ret = cv2.imencode('.jpg', img)\n",
    "#      return Image(data=ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_class: Hat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-8675f7374bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#     show_img_jupyter(image_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#     image_result = cv2.resize(image_result, (int(columns ), int(lines )))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrayShow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-601c025d22c6>\u001b[0m in \u001b[0;36marrayShow\u001b[0;34m(imageArray)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0marrayShow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import PIL\n",
    "\n",
    "from io import BytesIO as StringIO\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "     #Running time calculate (start)\n",
    "    time_start=time.clock()\n",
    "    clear_output(wait=True)\n",
    "    sucess,image=cap.read()\n",
    "    \n",
    "    lines, columns, _ =image.shape \n",
    "    #注释\n",
    "    \n",
    "    \"\"\"Load image to DPU\"\"\"\n",
    "    #image_path = \"./image/input.jpg\"\n",
    "    #print(\"Loading picture from image folder...\")\n",
    "    #image = cv2.imread(image_path)\t\n",
    "    image_ho, image_wo, _ = image.shape\n",
    "    image_size = image.shape[:2]\n",
    "    image_data = pre_process(image, (416, 416))\n",
    "\n",
    "    image_data = np.array(image_data,dtype=np.float32)\n",
    "\n",
    "    input_len = n2cube.dpuGetInputTensorSize(task, CONV_INPUT_NODE)\n",
    "    \"\"\"Get input Tesor\"\"\"\n",
    "    n2cube.dpuSetInputTensorInHWCFP32(task,CONV_INPUT_NODE,image_data,input_len)\n",
    "\n",
    "    \"\"\"Model run on DPU\"\"\"\n",
    "    n2cube.dpuRunTask(task)\n",
    "    \n",
    "    conv_sbbox_size = n2cube.dpuGetOutputTensorSize(task, CONV_OUTPUT_NODE1)\n",
    "    conv_out1 = n2cube.dpuGetOutputTensorInHWCFP32(task, CONV_OUTPUT_NODE1, conv_sbbox_size)\n",
    "    conv_out1 = np.reshape(conv_out1, (1, 13, 13, 18))\n",
    "\n",
    "    conv_mbbox_size = n2cube.dpuGetOutputTensorSize(task, CONV_OUTPUT_NODE2)\n",
    "    conv_out2 = n2cube.dpuGetOutputTensorInHWCFP32(task, CONV_OUTPUT_NODE2, conv_mbbox_size)\n",
    "    conv_out2 = np.reshape(conv_out2, (1, 26, 26, 18))\n",
    "\n",
    "    #conv_fps=1/(time.perf_counter()-conv_time_start)\n",
    "    #print('Convolution Speed: %s FPS'%(1/(time.perf_counter()-conv_time_start))) # <------------ Convolution Time Printing\n",
    "\n",
    "    yolo_outputs = [conv_out1, conv_out2]\n",
    "\n",
    "    \"\"\"Post-processing\"\"\"   \n",
    "    out_boxes, out_scores, out_classes = eval(yolo_outputs, image_size ,class_names, anchors)\n",
    "\n",
    "    \"\"\" Running time calculate(over) and print \"\"\"\t\n",
    "    run_fps=1/(time.clock()-time_start)\n",
    "    #print('Running Speed: %s FPS'%(1/(time_end-time_start)))\n",
    "\n",
    "\n",
    "    items = []\n",
    "    draws = []\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image_ho, np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image_wo, np.floor(right + 0.5).astype('int32'))\n",
    "        draw  = [left, top, right, bottom, score, c]\n",
    "        item  = [predicted_class, score, left, top, right, bottom]\n",
    "        draws.append(draw)\n",
    "        items.append(item)\n",
    "        print(\"predicted_class:\",predicted_class)\n",
    "        text_image = cv2.putText(image, predicted_class+':'+str(round(score,2)), (left,top-10), cv2.FONT_ITALIC, 0.6, (122, 0, 204), 2)\n",
    "\n",
    "\n",
    "#     image = cv2.putText(image, 'Convolution FPS'+':'+str(round(conv_fps,2)), (0,20), cv2.FONT_ITALIC, 0.6, (122, 0, 204), 2)\n",
    "    image = cv2.putText(image, 'Total FPS'+':'+str(round(run_fps,2)), (0,40), cv2.FONT_ITALIC, 0.6, (122, 0, 204), 2)\n",
    "\n",
    "    image_result = draw_bbox(image, draws, class_names)\n",
    "#     show_img_jupyter(image_result)\n",
    "#     image_result = cv2.resize(image_result, (int(columns ), int(lines )))\n",
    "    display(arrayShow(image_result))\n",
    "    \n",
    "    time.sleep(0.01)\n",
    "#     if KeyboardInterrupt:\n",
    "#         cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
